{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Въведение в Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Целите днес:\n",
    "\n",
    "* Да си подкараме jupyter, scikit-learn и всичко останало\n",
    "* Вид на входните данни\n",
    "* Видове machine learning: (supervised и unsupervised)\n",
    "* Няколко алгоритъма отгоре-отгоре"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Нужните технологии\n",
    "\n",
    "Трябват ви jupyter, scikit-learn и няколко други технологии. Имате два начина да ги подкарате:\n",
    "\n",
    "* `pip install`\n",
    "* Anaconda (https://anaconda.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Ние предпочитаме първия подход, понеже сме относително уверени в Python и ни е по-прозрачно така.\n",
    "Бихме ви предложили да направите същото. Разбира се, може да пробвате и Anaconda.\n",
    "Няма голямо значение кое от двете ще изберете, стига да ви е комфортно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `pip install`\n",
    "\n",
    "За да начало са ви нужни следните неща:\n",
    "\n",
    "```\n",
    "pip install numpy scipy matplotlib ipython scikit-learn pandas pillow mglearn jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Конкретно:\n",
    "\n",
    "* numpy, scipy – библиотеки за \"работа с числа\"\n",
    "* matplotlib, pillow – чертане на графики\n",
    "* scikit-learn – machine learning, тук се случва магията\n",
    "* ipython – по-шантава интерактивна конзола\n",
    "* jupyter – система за notebooks за Python (и други)\n",
    "* pandas – библиотека за анализ на данни\n",
    "* mglearn – библиотеката на [Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do), има полезни функции за чертане"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Веднъж като сте качили всичко това, просто изпълнете в терминала:\n",
    "\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "Това ще ви отвори браузър, където може да започнете работа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Anaconda\n",
    "\n",
    "Идете на сайта и си го изтеглете. Нататък сте вие самите.\n",
    "\n",
    "https://anaconda.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Jupyter\n",
    "\n",
    "За начало, нека разгледаме Jupyter.\n",
    "\n",
    "* Интерактивна среда в notebook формат\n",
    "* Позволява ви да изпълнявате код и да чертаете диаграми на едно място\n",
    "* Експериментално ще го ползваме за слайдове и материали (като тази лекция, например)\n",
    "\n",
    "Demo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Jupyter е интерактивна среда, която ви позволява да изпълнявате код и да чертаете диаграми в notebook формат. Тя е много подходяща за експериментиране с модели. Допълнително, може да споделите изследванията с някой като му пратите готов notebook. Например, тази лекция е един голям jupyter notebook, който ползваме едновремено за примери и слайдове. Части от нея (като този параграф) няма да бъдат достъпни в слайдовете, но ще може да разгледате впоследствие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Python е относително прост език за програмиране. Ще ви го разкажем в по-късна лекция – засега примерите ще бъдат частично разбираеми, частично черна магия. Не се притеснявайте ако нещо не ви е ясно. Избрали сме го, защото той има най-добрите библиотеки за machine learning. Авторите на тези библиотеки пък са го избрали, защото е много лесен за научаване.\n",
    "\n",
    "Стефан го мрази със страст. Може да го разпитате в някое междучасие. Нека това да не ви обезсърчава – обективно погледнато е добър език, особено за този тип проблеми."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Долното парче код ще ви е нужно в повечето jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning\n",
    "\n",
    "Проблемите, подходящи за \"машинно самообучение\", имат следните качества:\n",
    "\n",
    "* Големи масиви от данни\n",
    "* \"Нагаждаме\" различни алгоритми към проблема, докато постигнем резултат\n",
    "* Тренираме модел, който ни позволява да отговорим на въпроси за нови данни\n",
    "* Rule of thumb: ако човек може да реши проблема за около 2 секунди, вероятно може да направим ML решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Някои интересности:\n",
    "\n",
    "* Повече данни могат да ни помогнат да постигнем по-добър резлутат (до един момент)\n",
    "* При коренно различни данни може да се наложи да ползваме друг алгоритъм\n",
    "* Всичко е проба и грешка – трябва да пробваме различни алгоритми и да разбираме какво се случва\n",
    "* Има много пинизи и дребни детайли"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Математика\n",
    "\n",
    "Каква математика ще ви е нужна? Кратката версия:\n",
    "\n",
    "$$ y = ax + b $$\n",
    "\n",
    "(където $y$ и $b$ са вектори, а $a$ и $x$ са матрици)\n",
    "\n",
    "Дългата версия е по-сложна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Малко по-детайлно:\n",
    "\n",
    "Задължително ще ви трябва да разбирате от поне малко линейна алгебра. Като начало, трябва да разбирате от умножение на матрици и да ви е относително комфортно да го правите. Това е едно добро начало.\n",
    "\n",
    "В подробности – всеки алгоритъм си има особеностите и математиката, свързана с него. Линейната регресия е напълно разбираема с познания от първи семестър, първи курс. Други алгоритмни като Support Vector Machines или Principal Component Analysis са по-сложни и искат повече познания. На практика, може да стигнете доста далеч с повърхностно разбиране на тези алгоритми. На теория, колкото повече математика знаете, толкова по-добре ще се оправите.\n",
    "\n",
    "За целите на курса ще се нуждаем единствено от уравнението по-горе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Входни данни\n",
    "\n",
    "Обикновено работим с таблица от входни данни:\n",
    "\n",
    "* Всеки ред е определена инстанция (например различен човек)\n",
    "* Всяка колона е характерискита на този човек (възраст, брой деца, т.н.)\n",
    "* Характеристиките още се наричат (на чист български) feature-и\n",
    "* Опционално към всеки ред може да има отговор на въпроса, за който правим модел (още се нарича label)\n",
    "* Засега нека приемем, че клетки съдържат числа (текста може да се сведе до много feature-и)\n",
    "* Обикновено разглеждаме данните като матрица $X$, а етикетите (label-ите) като вектор $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| Възраст | Коли | Къща | Деца | Женен?   | Куче? | Купува лодка? |\n",
    "|---------|------|------|------|----------|-------|:-------------:|\n",
    "| 66      | 1    | да   | 2    | вдовец   | не    | **да**        |\n",
    "| 52      | 2    | не   | 3    | женен    | не    | **да**        |\n",
    "| 22      | 0    | не   | 0    | женен    | да    | **не**        |\n",
    "| 25      | 1    | не   | 1    | неженен  | не    | **не**        |\n",
    "| 44      | 0    | не   | 2    | разведен | не    | **не**        |\n",
    "| 39      | 1    | да   | 2    | женен    | да    | **не**        |\n",
    "| 26      | 1    | не   | 2    | неженен  | не    | **не**        |\n",
    "| 40      | 3    | да   | 1    | женен    | да    | **не**        |\n",
    "| 53      | 2    | да   | 2    | разведен | не    | **да**        |\n",
    "| 64      | 2    | да   | 3    | разведен | не    | **да**        |\n",
    "| 58      | 2    | да   | 2    | женен    | да    | **да**        |\n",
    "| 33      | 1    | не   | 1    | неженен  | не    | **не**        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "На първите 6 колони от предната таблица може да гледате като матрицата $X$, докато на последната колона като вектора $y$.\n",
    "\n",
    "Булевите данни могат да се кодират като числата 0 и 1, а енумерациите (женен?) като серия от числа. Различни репрезентации може да са подходящи за различни алгоритми.\n",
    "\n",
    "Конвенцията $X$ и $y$ ще се ползва постоянно, така че е добре да свикнете с нея. Когато се опитваме да отговаряме на въпроси (тези хора биха ли си купили лодка?), ще подаваме хората като матрица $X$ и ще очакваме да получим вектор $y$, където всеки елемент от вектора ще съдържа отговор дали този човек би си купил лодка.\n",
    "\n",
    "Работата с текст обикновено се свежда до извличане на скаларни feature-и от данните (например колоните могат да съответстват на уникални думи в документа, докато клетките – на брой срещания). Това е по-дълбока вода, която ще покрием по-натам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Примерни набори от данни\n",
    "\n",
    "scikit-learn предлага няколко набора от примерни данни с които може да работите.\n",
    "\n",
    "* boston\n",
    "* iris\n",
    "* diabetes\n",
    "* digits\n",
    "* linnerud\n",
    "* wine\n",
    "* breast_cancer\n",
    "\n",
    "Всички те могат да се ползват за прости експерименти и илюстрация на моделите. Дори ще ползваме някои."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ако искате да ползвате определен dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# boston demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Ето описание на boston dataset-а:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Данните са в `boston.data`, имената на feature-ите са в `boston.feature_names` (съответстват не тези кратки съкращения по-горе), а очакваната цел е в `boston.target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "boston.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Обърнете внимание, че това не са Python масиви, ами NumPy вектори и матрици."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Синтетични набори от данни\n",
    "\n",
    "scikit-learn предлага и някои синтетични набори от данни. Понякога и те са интересни.\n",
    "\n",
    "Любопитен пример е `make_moons`, който прави два полумесеца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n",
    "\n",
    "plt.close()\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Този dataset е по-лесно разбираем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Впрочем, ето невронна мрежа, която разпознава граница между двата класа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "plt.close()\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', random_state=0).fit(X, y)\n",
    "mglearn.plots.plot_2d_separator(mlp, X, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Горният код има няколко проблема, в които ще влезем по-натам. Засега просто искаме да ви покажем малко графики, не да разберем как работят невронните мрежи (което е дълъг и сложен въпрос)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Повече за sklearn.datasets\n",
    "\n",
    "Повече информация за наборите от данни в scikit-learn може да намерите в документацията:\n",
    "\n",
    "http://scikit-learn.org/stable/datasets/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supervised vs. unsupervised learning\n",
    "\n",
    "Алгоритмите могат да се разделят на два видя:\n",
    "\n",
    "* Supervised learning – такива, които разполагат с labelled данни и генерализират (да отговарят на въпроси за нови данни)\n",
    "* Unsupervised learning – такива, които нямат label-и и трябва да открият статистически зависимости в данните"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Supervised learning\n",
    "\n",
    "Примери за supervised learning са:\n",
    "\n",
    "* При набор от данни с цени и параметри на апартаменти да определим колко би струвал друг апартамент с определени апартаменти.\n",
    "* При набор от данни за тумори да определим дали един е доброкачествен или злокачествен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Unsupervised learning\n",
    "\n",
    "Тези алгоритми са по-разнородни и приложими в определени сфери. Например:\n",
    "\n",
    "* При набор от потребители и техните филмови рейтинги да създадем групи от видове предпочитания\n",
    "* При набор от многомерни данни данни да сведем броя измерения до по-малък такъв запазвайки повечето информация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Регресия vs. Класификация\n",
    "\n",
    "Бихме могли да разделим supervised learning на два вида:\n",
    "\n",
    "* Регресия – опитваме се да сведем данните до непрекъсната стойност (цена на апартамент)\n",
    "* Класификация – опитваме се да определим данните дали попадат в една от две категории (доброкачествен или злокачествен тумор)\n",
    "\n",
    "Стандартен подход за класификация с 3+ класа е one-vs-many – създаваме по един класификатор за всяка категория, прекарваме данните през тях и избираме най-вероятната."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Няколко алгоритъма\n",
    "\n",
    "Сега ще разгледаме няколко алгоритъма отгоре-отгоре. Целта е да разберем как работят концептуално. Ще разгледаме всеки от тях в детайли в следващи лекции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Disclaimer\n",
    "\n",
    "Ще гледаме набори от данни с едно или две измерения. Те са доста лесни за визуализация, но рядко реалистични – обикновено работим със десетки, стотици или дори хиляди feature-а (т.е. измерения). Това е далеч по-трудно за визуализация, откъдето идва и голяма част от предизвикателството."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# k-Nearest Neighbours (kNN)\n",
    "\n",
    "### Supervised, класификация\n",
    "\n",
    "Възможно най-простия алгоритъм.\n",
    "\n",
    "Запазва целия dataset. За да класифицира нов елемнт намира най-близкия (линейно, в евклидово пространство) до него и отговаря със същия клас:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Предния пример гледаше 1 най-близък съсед. Може да се имплементира да гледа няколко:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Броят съседи определя колко \"гладка\" е границата между двата класа. Ето един пример с различен брой съседи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X, y)\n",
    "    mglearn.plots.plot_2d_separator(clf, X, fill=True, eps=0.5, ax=ax, alpha=.4)\n",
    "    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    "    ax.set_title(\"{} neighbour(s)\".format(n_neighbors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Фонът в горната диаграма определя в кой от двата класа ще попадне дадена точка. Обърнете внимание, че при k=1 границата е начупена и хваща всеки елемент. При по-голямо k границата става по-плавна, макар и да класифицира някои елементи грешно. Това може да е предимство (ще игнорира аномалии в данните). Ще видим вариации на тази тема по-натам с нормализация в линейните модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression\n",
    "### Supervised, регресия\n",
    "\n",
    "Най-популярният модел. Опитва се да намери линейна функция, която приближава данните. С обработка на feature-ите може да намира и нелинейни функци, но това следващия път."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_linear_regression_wave()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Алгоритъмът се опитва да намери линейна функция, която минимизира общата грешката (сумата от квадратите на дистанцията между резултата от линейната функция и y координата на всеки елемент от набора от данни). В горния е трудно да се направи по-точен линеен модел, тъй като данните имат голяма вариация за едни и същи входни стойности. При наличието на повече измерения обикновено може да се постигне по-добър резултат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Principal Component Analysis\n",
    "### Unsupervised, dimensionality reduction\n",
    "\n",
    "Можете да сведете многомерно пространство до такова с по-малко измерения, които запазват (почти напълно) същата информация.\n",
    "\n",
    "Може да се ползва за feature selection – да намалите броя характеристики с които тренирате модел, свеждайки ги до по-малко."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_pca_illustration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Графиките горе илюстрират как PCA се опитва да сведе двуизмерно пространство до едноизмерно. Данните могат да се представят чрез базис от два вектора (component 1 и component 2), където component 1 съдържа много информация, а component 2 – малко. С този dataset бихме могли да тренираме относително точен модел само с component 1. Обърнете внимание, че той е функция на оригиналните два feature-а.\n",
    "\n",
    "При две измерения това не е нужно, но при 1000+ подобна трансформация на данните може да е задължителна за да има шанс да съберете модела в паметта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# k-Means Clustering\n",
    "### Unsupervised, клъстеризация\n",
    "\n",
    "Опитва се да раздели данните на определен брой клъстери."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    " mglearn.plots.plot_kmeans_algorithm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Този алгоритъм е относително магически. Работи по следния начин:\n",
    "\n",
    "1. Избира три произволни точки.\n",
    "2. За всяка точка оцветява данните, за които тя е най-близка.\n",
    "3. Преизчислява центъра на всеки клъстър от точки от един цвят и мести точката там.\n",
    "4. Връща се на стъпка 2 и повтаря докато се стабилизира.\n",
    "\n",
    "Този алгоритъм е недетерминистичен – различен избор на първоначални точки може да произведе различни резултати. По тази причина на практика се изпълнява няколко пъти и се взема добър резултат.\n",
    "\n",
    "Това също е мотив, който се среща често."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Обобщение\n",
    "\n",
    "* Матрица от данни $X$ и резултат $y$\n",
    "* Supervised vs. unsupervised learning\n",
    "* Регресия и класификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ресурси\n",
    "\n",
    "* [Introduction to Machine Learning](http://shop.oreilly.com/product/0636920030515.do)\n",
    "* [Machine Learning course by Andrew Ng](https://www.coursera.org/learn/machine-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Въпроси\n",
    "\n",
    "* http://fmi.machine-learning.bg\n",
    "* fmi@machine-learning.bg"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
